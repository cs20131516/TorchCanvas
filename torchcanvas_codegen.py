# torchcanvas_codegen.py
# TorchCanvas: Graph(JSON) → PyTorch code package exporter
# 사용: python torchcanvas_codegen.py --graph graph.json --name MyModel --out ./generated --with-train

import json, argparse, textwrap
from pathlib import Path

# ----------------------------
# 템플릿: blocks.py
# ----------------------------
BLOCKS_PY = """\
# Auto-generated by TorchCanvas Code Export
import torch
import torch.nn as nn

class GRUBlock(nn.Module):
    \"""
    GRU + output normalization
    - input: (B, T, H_in)
    - out: 'last' | 'mean' | 'max' | 'seq'
    \"""
    def __init__(self, hidden_size:int, num_layers:int=1, bidirectional:bool=True, out:str="last"):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.bidirectional = bidirectional
        self.out_mode = out
        self.gru = None  # lazy init at first forward

    def forward(self, x):
        if x.ndim != 3:
            raise ValueError(f"GRUBlock expects 3D (B,T,H), got {tuple(x.shape)}")
        if self.gru is None:
            self.gru = nn.GRU(
                input_size=x.size(-1),
                hidden_size=self.hidden_size,
                num_layers=self.num_layers,
                bidirectional=self.bidirectional,
                batch_first=True,
            ).to(x.device, x.dtype)
        y, _ = self.gru(x)
        if self.out_mode == "seq":
            return y
        if self.out_mode == "last":
            return y[:, -1, :]
        if self.out_mode == "mean":
            return y.mean(dim=1)
        if self.out_mode == "max":
            return y.max(dim=1).values
        raise ValueError(f"Unknown out mode: {self.out_mode}")
"""

# ----------------------------
# 템플릿: model.py (그래프 주입)
# ----------------------------
def render_model_py(class_name:str, nodes, edges, inputs, outputs):
    node_types = {n["id"]: n["type"] for n in nodes}
    node_params = {n["id"]: n.get("params", {}) for n in nodes}

    # in-edges
    in_edges = {n["id"]: [] for n in nodes}
    for src, dst in edges:
        in_edges[dst].append(src)

    # topo sort
    indeg = {n["id"]: 0 for n in nodes}
    adj = {}
    for src, dst in edges:
        indeg[dst] += 1
        adj.setdefault(src, []).append(dst)
    q = [nid for nid, d in indeg.items() if d == 0]
    order = []
    while q:
        u = q.pop()
        order.append(u)
        for v in adj.get(u, []):
            indeg[v] -= 1
            if indeg[v] == 0:
                q.append(v)
    if len(order) != len(nodes):
        raise ValueError("Graph has cycle or disconnected parts.")

    # __init__ lines
    init_lines = []
    for nid in order:
        typ = node_types[nid]
        if typ == "Input":
            continue
        p = node_params[nid]
        if typ == "Conv1d":
            pad = p.get("padding", "same")
            pad_expr = f"{p.get('kernel_size')} // 2" if pad == "same" else str(int(pad))
            init_lines.append(
                f"self.{nid} = nn.LazyConv1d({p['out_channels']}, {p['kernel_size']}, stride={p.get('stride',1)}, padding={pad_expr}, bias=True)"
            )
        elif typ == "BatchNorm1d":
            num = p.get("num_features", None)
            if num in (None, 0):
                init_lines.append(f"self.{nid} = nn.LazyBatchNorm1d()")
            else:
                init_lines.append(f"self.{nid} = nn.BatchNorm1d({num})")
        elif typ == "Linear":
            init_lines.append(f"self.{nid} = nn.LazyLinear({p['out_features']}, bias={p.get('bias', True)})")
        elif typ == "ReLU":
            init_lines.append(f"self.{nid} = nn.ReLU(inplace=True)")
        elif typ == "Dropout":
            init_lines.append(f"self.{nid} = nn.Dropout({p.get('p', 0.5)})")
        elif typ == "MaxPool1d":
            ks = p.get("kernel_size", 2); st = p.get("stride", None)
            init_lines.append(
                f"self.{nid} = nn.MaxPool1d(kernel_size={ks}{', stride='+str(st) if st is not None else ''})"
            )
        elif typ == "GRUBlock":
            hs = p["hidden_size"]; nl = p.get("num_layers", 1); bd = p.get("bidirectional", True)
            outm = repr(p.get("out", "last"))
            init_lines.append(f"self.{nid} = GRUBlock(hidden_size={hs}, num_layers={nl}, bidirectional={bd}, out={outm})")
        elif typ in ("Concat","Permute_BCT_to_BTH","Permute_BTH_to_BCT"):
            init_lines.append(f"# {typ} '{nid}' has no parameters")
        else:
            init_lines.append(f"# TODO: Unsupported node type '{typ}'")

    # forward lines
    fwd = []
    fwd.append("cache = {}")
    for inp in inputs:
        fwd.append(f"cache['{inp}'] = inputs['{inp}']")

    for nid in order:
        typ = node_types[nid]
        if typ == "Input":
            continue
        srcs = in_edges[nid]
        if typ == "Concat":
            dim = node_params[nid].get("dim", 1)
            src_list = ", ".join([f"cache['{s}']" for s in srcs])
            fwd.append(f"cache['{nid}'] = torch.cat([{src_list}], dim={dim})")
        elif typ == "Permute_BCT_to_BTH":
            fwd.append(f"cache['{nid}'] = cache['{srcs[0]}'].transpose(1, 2).contiguous()")
        elif typ == "Permute_BTH_to_BCT":
            fwd.append(f"cache['{nid}'] = cache['{srcs[0]}'].transpose(1, 2).contiguous()")
        elif typ in ("Conv1d","BatchNorm1d","Linear","ReLU","Dropout","MaxPool1d","GRUBlock"):
            fwd.append(f"cache['{nid}'] = self.{nid}(cache['{srcs[0]}'])")
        else:
            fwd.append(f"# TODO: forward for '{typ}'")

    if len(outputs) == 1:
        fwd.append(f"return cache['{outputs[0]}']")
    else:
        pairs = ", ".join([f"'{k}': cache['{k}']" for k in outputs])
        fwd.append(f"return {{ {pairs} }}")

    init_body = "\n        ".join(init_lines)
    fwd_body  = "\n        ".join(fwd)

    model_py = f"""\
# Auto-generated by TorchCanvas Code Export
import torch
import torch.nn as nn
from .blocks import GRUBlock

class {class_name}(nn.Module):
    def __init__(self):
        super().__init__()
        {init_body}

    def forward(self, inputs: dict):
        {fwd_body}
"""
    return model_py

# ----------------------------
# 템플릿: train.py (옵션)
# ----------------------------
TRAIN_PY = """\
# Auto-generated training skeleton for TorchCanvas export
import torch, torch.nn as nn, torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from .model import ExportedModel

def demo_train(epochs=3, batch_size=8, C=9, T=256, num_classes=18, lr=1e-3, device='cpu'):
    model = ExportedModel().to(device)
    # dummy dataset
    X = torch.randn(128, C, T)
    y = torch.randint(0, num_classes, (128,))
    ds = TensorDataset(X, y)
    dl = DataLoader(ds, batch_size=batch_size, shuffle=True)

    opt = optim.AdamW(model.parameters(), lr=lr)
    crit = nn.CrossEntropyLoss()

    model.train()
    for ep in range(1, epochs+1):
        total = 0.0
        for xb, yb in dl:
            xb, yb = xb.to(device), yb.to(device)
            logits = model({"inp": xb})
            loss = crit(logits, yb)
            opt.zero_grad()
            loss.backward()
            opt.step()
            total += loss.item() * xb.size(0)
        print(f"[ep {ep}] loss={(total/len(ds)):.4f}")

if __name__ == "__main__":
    demo_train()
"""

# ----------------------------
# 코드 생성기
# ----------------------------
def export_code(graph_path: Path, name: str, out_dir: Path, with_train: bool):
    g = json.loads(Path(graph_path).read_text(encoding="utf-8"))
    nodes = g["nodes"]; edges = g["edges"]; inputs = g["inputs"]; outputs = g["outputs"]

    pkg_dir = out_dir / name
    pkg_dir.mkdir(parents=True, exist_ok=True)

    # __init__.py
    (pkg_dir / "__init__.py").write_text("from .model import ExportedModel\n", encoding="utf-8")

    # blocks.py
    (pkg_dir / "blocks.py").write_text(BLOCKS_PY, encoding="utf-8")

    # model.py
    model_code = render_model_py("ExportedModel", nodes, edges, inputs, outputs)
    (pkg_dir / "model.py").write_text(model_code, encoding="utf-8")

    # (optional) train.py
    if with_train:
        (pkg_dir / "train.py").write_text(TRAIN_PY, encoding="utf-8")

    # README snippet
    readme = f"# {name}\n\nGenerated by TorchCanvas Code Export.\n\n```\nfrom {name} import ExportedModel\nm = ExportedModel()\n```\n"
    (pkg_dir / "README.md").write_text(readme, encoding="utf-8")

    print(f"[OK] Exported package → {pkg_dir}")

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--graph", required=True, help="Graph JSON path")
    ap.add_argument("--name",  required=True, help="Python package name (e.g., HybridCMI)")
    ap.add_argument("--out",   default="./generated", help="Output root directory")
    ap.add_argument("--with-train", action="store_true", help="Emit train.py skeleton")
    args = ap.parse_args()

    export_code(Path(args.graph), args.name, Path(args.out), args.with_train)

if __name__ == "__main__":
    main()
