# app.py â€” TorchCanvas Mini GUI (Graph â†’ PyTorch ì½”ë“œ ë¯¸ë¦¬ë³´ê¸°/ë‹¤ìš´ë¡œë“œ)
# ì‹¤í–‰: streamlit run app.py
import json
from dataclasses import dataclass, field
from typing import Dict, List, Any
import streamlit as st
import streamlit.components.v1 as components

st.set_page_config(page_title="TorchCanvas â€” Code Preview", layout="wide")

# ---------- ê°œì„ ëœ ë…¸ë“œ íƒ€ì… ìŠ¤í™ (ì¹´í…Œê³ ë¦¬ë³„) ----------
NODE_SPECS = {
    # ì…ë ¥/ì¶œë ¥
    "Input": {
        "params": {},
        "category": "io",
        "color": "#28a745",
        "icon": "ğŸ“¥",
        "description": "ëª¨ë¸ ì…ë ¥"
    },
    "Output": {
        "params": {},
        "category": "io", 
        "color": "#17a2b8",
        "icon": "ğŸ“¤",
        "description": "ëª¨ë¸ ì¶œë ¥"
    },
    
    # ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´
    "Conv1d": {
        "params": {"out_channels": int, "kernel_size": int, "stride": (int, 1), "padding": ("same_or_int", "same")},
        "category": "conv",
        "color": "#ffc107",
        "icon": "ğŸ”²",
        "description": "1D ì»¨ë³¼ë£¨ì…˜"
    },
    "Conv2d": {
        "params": {"out_channels": int, "kernel_size": int, "stride": (int, 1), "padding": ("same_or_int", "same")},
        "category": "conv",
        "color": "#ffc107", 
        "icon": "ğŸ”²",
        "description": "2D ì»¨ë³¼ë£¨ì…˜"
    },
    
    # ì •ê·œí™” ë ˆì´ì–´
    "BatchNorm1d": {
        "params": {"num_features": (int, 0)},
        "category": "norm",
        "color": "#6f42c1",
        "icon": "ğŸ“Š",
        "description": "1D ë°°ì¹˜ ì •ê·œí™”"
    },
    "BatchNorm2d": {
        "params": {"num_features": (int, 0)},
        "category": "norm",
        "color": "#6f42c1",
        "icon": "ğŸ“Š", 
        "description": "2D ë°°ì¹˜ ì •ê·œí™”"
    },
    
    # í™œì„±í™” í•¨ìˆ˜
    "ReLU": {
        "params": {},
        "category": "activation",
        "color": "#007bff",
        "icon": "âš¡",
        "description": "ReLU í™œì„±í™”"
    },
    "Sigmoid": {
        "params": {},
        "category": "activation", 
        "color": "#007bff",
        "icon": "ğŸ“ˆ",
        "description": "Sigmoid í™œì„±í™”"
    },
    "Tanh": {
        "params": {},
        "category": "activation",
        "color": "#007bff", 
        "icon": "ğŸ“ˆ",
        "description": "Tanh í™œì„±í™”"
    },
    
    # í’€ë§ ë ˆì´ì–´
    "MaxPool1d": {
        "params": {"kernel_size": (int, 2), "stride": (int, None)},
        "category": "pool",
        "color": "#fd7e14",
        "icon": "ğŸ”½",
        "description": "1D ìµœëŒ€ í’€ë§"
    },
    "MaxPool2d": {
        "params": {"kernel_size": (int, 2), "stride": (int, None)},
        "category": "pool",
        "color": "#fd7e14",
        "icon": "ğŸ”½",
        "description": "2D ìµœëŒ€ í’€ë§"
    },
    "AvgPool2d": {
        "params": {"kernel_size": (int, 2), "stride": (int, None)},
        "category": "pool",
        "color": "#fd7e14",
        "icon": "ğŸ”½",
        "description": "2D í‰ê·  í’€ë§"
    },
    
    # ì™„ì „ì—°ê²° ë ˆì´ì–´
    "Linear": {
        "params": {"out_features": int, "bias": (bool, True)},
        "category": "fc",
        "color": "#e83e8c",
        "icon": "ğŸ”—",
        "description": "ì™„ì „ì—°ê²° ë ˆì´ì–´"
    },
    
    # ìœ í‹¸ë¦¬í‹°
    "Dropout": {
        "params": {"p": (float, 0.5)},
        "category": "util",
        "color": "#6c757d",
        "icon": "ğŸ²",
        "description": "ë“œë¡­ì•„ì›ƒ"
    },
    "Flatten": {
        "params": {"start_dim": (int, 1), "end_dim": (int, -1)},
        "category": "util",
        "color": "#6c757d",
        "icon": "ğŸ“",
        "description": "í…ì„œ í‰íƒ„í™”"
    },
    
    # ê²°í•© ì—°ì‚°
    "Concat": {
        "params": {"dim": (int, 1)},
        "category": "combine",
        "color": "#20c997",
        "icon": "ğŸ”—",
        "description": "í…ì„œ ì—°ê²°"
    },
    "Add": {
        "params": {},
        "category": "combine",
        "color": "#20c997",
        "icon": "â•",
        "description": "í…ì„œ ë§ì…ˆ"
    },
    
    # ìˆœì—´ ì—°ì‚°
    "Permute_BCT_to_BTH": {
        "params": {},
        "category": "permute",
        "color": "#6f42c1",
        "icon": "ğŸ”„",
        "description": "BCT â†’ BTH ë³€í™˜"
    },
    "Permute_BTH_to_BCT": {
        "params": {},
        "category": "permute", 
        "color": "#6f42c1",
        "icon": "ğŸ”„",
        "description": "BTH â†’ BCT ë³€í™˜"
    },
    
    # ìˆœí™˜ ì‹ ê²½ë§
    "GRUBlock": {
        "params": {
            "hidden_size": int, "num_layers": (int, 1), "bidirectional": (bool, True),
            "out": (["last","mean","max","seq"], "last")
        },
        "category": "rnn",
        "color": "#dc3545",
        "icon": "ğŸ”„",
        "description": "GRU ë¸”ë¡"
    },
    
    # ì»´í¬ì§€íŠ¸ ë¸”ë¡ë“¤
    "SEBlock": {
        "params": {"reduction": (int, 8)},
        "category": "composite",
        "color": "#28a745",
        "icon": "ğŸ¯",
        "description": "Squeeze-and-Excitation"
    },
    "ResidualBlock": {
        "params": {"out_channels": int, "kernel_size": (int, 3), "stride": (int, 1)},
        "category": "composite",
        "color": "#28a745",
        "icon": "â­ï¸",
        "description": "ì”ì°¨ ë¸”ë¡"
    },
    "VGGBlock": {
        "params": {
            "c1": int, "c2": int, "kernel_size": (int, 3), 
            "use_lrn": (bool, False), "pool": (bool, True)
        },
        "category": "composite",
        "color": "#28a745",
        "icon": "ğŸ—ï¸",
        "description": "VGG ìŠ¤íƒ€ì¼ ë¸”ë¡"
    },
}

# ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í•‘
CATEGORIES = {
    "io": "ì…ë ¥/ì¶œë ¥",
    "conv": "ì»¨ë³¼ë£¨ì…˜", 
    "norm": "ì •ê·œí™”",
    "activation": "í™œì„±í™”",
    "pool": "í’€ë§",
    "fc": "ì™„ì „ì—°ê²°",
    "util": "ìœ í‹¸ë¦¬í‹°",
    "combine": "ê²°í•©",
    "permute": "ìˆœì—´",
    "rnn": "ìˆœí™˜ì‹ ê²½ë§",
    "composite": "ì»´í¬ì§€íŠ¸"
}

# ---------- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ----------
def _init_state():
    ss = st.session_state
    ss.setdefault("nodes", [])    # type: ignore[assignment]  â† í•„ìš”ì‹œ
    ss.setdefault("edges", [])
    ss.setdefault("inputs", [])
    ss.setdefault("outputs", [])
    ss.setdefault("tensor_shapes", {})  # ë…¸ë“œë³„ í…ì„œ í˜•íƒœ ì €ì¥
_init_state()

# ---------- í…ì„œ í˜•íƒœ ì¶”ì • í•¨ìˆ˜ ----------
def estimate_tensor_shape(node_id: str, node_type: str, params: dict, input_shapes: List[tuple]) -> tuple:
    """ë…¸ë“œì˜ ì¶œë ¥ í…ì„œ í˜•íƒœë¥¼ ì¶”ì •"""
    if not input_shapes:
        return (1, 3, 224, 224)  # ê¸°ë³¸ ì…ë ¥ í˜•íƒœ
    
    input_shape = input_shapes[0]  # ì²« ë²ˆì§¸ ì…ë ¥ ì‚¬ìš©
    
    if node_type == "Input":
        return input_shape
    
    elif node_type == "Conv2d":
        B, C, H, W = input_shape
        out_channels = params.get("out_channels", 64)
        kernel_size = params.get("kernel_size", 3)
        stride = params.get("stride", 1)
        padding = params.get("padding", "same")
        
        if padding == "same":
            pad = kernel_size // 2
        else:
            pad = int(padding)
        
        H_out = (H + 2 * pad - kernel_size) // stride + 1
        W_out = (W + 2 * pad - kernel_size) // stride + 1
        return (B, out_channels, H_out, W_out)
    
    elif node_type == "MaxPool2d":
        B, C, H, W = input_shape
        kernel_size = params.get("kernel_size", 2)
        stride = params.get("stride", kernel_size)
        
        H_out = (H - kernel_size) // stride + 1
        W_out = (W - kernel_size) // stride + 1
        return (B, C, H_out, W_out)
    
    elif node_type == "ReLU":
        return input_shape  # í˜•íƒœ ìœ ì§€
    
    elif node_type == "LRN":
        return input_shape  # í˜•íƒœ ìœ ì§€
    
    elif node_type == "Flatten":
        B, C, H, W = input_shape
        return (B, C * H * W)
    
    elif node_type == "Linear":
        B = input_shape[0]
        out_features = params.get("out_features", 1000)
        return (B, out_features)
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ì…ë ¥ í˜•íƒœ ìœ ì§€
    return input_shape

# ---------- ê°œì„ ëœ ì‹œê°ì  ë„¤íŠ¸ì›Œí¬ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ----------
def create_network_diagram(nodes: List[dict], edges: List[List[str]], tensor_shapes: Dict[str, tuple]) -> str:
    """HTML/CSSë¡œ ë„¤íŠ¸ì›Œí¬ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±"""
    
    # ì˜ë¯¸ì—†ëŠ” ì—°ê²° í•„í„°ë§ (Input â†’ Output, ê°™ì€ íƒ€ì… ê°„ ì—°ê²° ë“±)
    def is_meaningful_edge(src_id: str, dst_id: str) -> bool:
        src_node = next((n for n in nodes if n["id"] == src_id), None)
        dst_node = next((n for n in nodes if n["id"] == dst_id), None)
        
        if not src_node or not dst_node:
            return False
        
        # Input â†’ Output ì—°ê²° ì œì™¸
        if src_node["type"] == "Input" and dst_node["type"] == "Output":
            return False
        
        # ê°™ì€ íƒ€ì… ê°„ ì§ì ‘ ì—°ê²° ì œì™¸ (ì˜ˆ: Conv1d â†’ Conv1d)
        if src_node["type"] == dst_node["type"] and src_node["type"] in ["Conv1d", "Conv2d", "BatchNorm1d", "BatchNorm2d"]:
            return False
        
        return True
    
    filtered_edges = [edge for edge in edges if is_meaningful_edge(edge[0], edge[1])]
    
    html = """
    <style>
    .network-container {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 30px;
        border-radius: 15px;
        margin: 10px 0;
        box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }
    .layers-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 20px;
        margin: 20px 0;
        position: relative;
        min-height: 400px;
    }
    .layer {
        background: white;
        border-radius: 12px;
        padding: 20px;
        text-align: center;
        position: relative;
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
        transition: all 0.3s ease;
        border-left: 5px solid;
        min-height: 150px;
        display: flex;
        flex-direction: column;
        justify-content: center;
    }
    .layer:hover {
        transform: translateY(-2px);
        box-shadow: 0 12px 35px rgba(0,0,0,0.2);
    }
    .layer-header {
        display: flex;
        align-items: center;
        justify-content: center;
        margin-bottom: 10px;
    }
    .layer-icon {
        font-size: 24px;
        margin-right: 10px;
    }
    .layer-name {
        font-weight: bold;
        font-size: 16px;
        margin: 0;
    }
    .layer-id {
        font-size: 12px;
        color: #6c757d;
        margin-top: 5px;
    }
    .tensor-shape {
        font-family: 'Courier New', monospace;
        background: linear-gradient(45deg, #f8f9fa, #e9ecef);
        padding: 8px 15px;
        border-radius: 8px;
        margin: 10px 0;
        font-size: 13px;
        font-weight: bold;
        border: 1px solid #dee2e6;
    }
    .status-check {
        position: absolute;
        top: 15px;
        right: 15px;
        color: #28a745;
        font-size: 20px;
        background: white;
        border-radius: 50%;
        width: 30px;
        height: 30px;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 2px 8px rgba(40, 167, 69, 0.3);
    }
    .params {
        font-size: 12px;
        color: #6c757d;
        margin-top: 10px;
        padding: 8px;
        background: #f8f9fa;
        border-radius: 6px;
        border-left: 3px solid #dee2e6;
    }
    .category-badge {
        position: absolute;
        top: 15px;
        left: 15px;
        font-size: 10px;
        padding: 4px 8px;
        border-radius: 12px;
        color: white;
        font-weight: bold;
        text-transform: uppercase;
    }
    .connection-info {
        background: rgba(255, 255, 255, 0.9);
        border-radius: 8px;
        padding: 15px;
        margin: 20px 0;
        text-align: center;
    }
    .connection-count {
        font-size: 18px;
        font-weight: bold;
        color: #667eea;
    }
    .connection-details {
        font-size: 14px;
        color: #6c757d;
        margin-top: 5px;
    }
    .warning {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 8px;
        padding: 15px;
        margin: 20px 0;
        color: #856404;
    }
    .connection-lines {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        pointer-events: none;
        z-index: 1;
    }
    .connection-line {
        stroke: #667eea;
        stroke-width: 2;
        fill: none;
        opacity: 0.7;
        marker-end: url(#arrowhead);
    }
    .layer {
        position: relative;
        z-index: 2;
    }
    </style>
    <div class="network-container">
    """
    
    # ì—°ê²° ì •ë³´ í‘œì‹œ
    meaningful_count = len(filtered_edges)
    total_count = len(edges)
    removed_count = total_count - meaningful_count
    
    html += f"""
    <div class="connection-info">
        <div class="connection-count">ğŸ”— ì—°ê²° ì •ë³´</div>
        <div class="connection-details">
            ìœ íš¨í•œ ì—°ê²°: {meaningful_count}ê°œ | 
            í•„í„°ë§ëœ ì—°ê²°: {removed_count}ê°œ | 
            ì´ ì—°ê²°: {total_count}ê°œ
        </div>
    </div>
    """
    
    if removed_count > 0:
        html += f"""
        <div class="warning">
            âš ï¸ {removed_count}ê°œì˜ ì˜ë¯¸ì—†ëŠ” ì—°ê²°ì´ ìë™ìœ¼ë¡œ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤.
            (Inputâ†’Output, ê°™ì€ íƒ€ì… ê°„ ì§ì ‘ ì—°ê²° ë“±)
        </div>
        """
    
    # ë…¸ë“œë“¤ì„ ê·¸ë¦¬ë“œ í˜•íƒœë¡œ ë°°ì¹˜
    html += '<div class="layers-grid" style="position: relative;">'
    
    # SVG ì—°ê²°ì„ ì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ
    html += '''
    <svg class="connection-lines" xmlns="http://www.w3.org/2000/svg">
        <defs>
            <marker id="arrowhead" markerWidth="10" markerHeight="7" 
                    refX="9" refY="3.5" orient="auto">
                <polygon points="0 0, 10 3.5, 0 7" fill="#667eea" />
            </marker>
        </defs>
    '''
    
    # ë…¸ë“œ ìœ„ì¹˜ ì¶”ì ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    node_positions = {}
    
    for i, node in enumerate(nodes):
        node_id = node["id"]
        node_type = node["type"]
        params = node.get("params", {})
        
        # í…ì„œ í˜•íƒœ ê°€ì ¸ì˜¤ê¸°
        input_shapes = []
        for src, dst in filtered_edges:
            if dst == node_id and src in tensor_shapes:
                input_shapes.append(tensor_shapes[src])
        
        if node_id in tensor_shapes:
            output_shape = tensor_shapes[node_id]
        else:
            output_shape = estimate_tensor_shape(node_id, node_type, params, input_shapes)
            st.session_state.tensor_shapes[node_id] = output_shape
        
        # íŒŒë¼ë¯¸í„° ë¬¸ìì—´ ìƒì„±
        param_str = ""
        if params:
            param_items = []
            for k, v in params.items():
                if isinstance(v, (int, float, bool)):
                    param_items.append(f"{k}={v}")
                elif isinstance(v, str):
                    param_items.append(f"{k}='{v}'")
            param_str = ", ".join(param_items)
        
        # ì¹´í…Œê³ ë¦¬ ìƒ‰ìƒ ê°€ì ¸ì˜¤ê¸°
        category_color = NODE_SPECS[node_type]["color"]
        category_name = NODE_SPECS[node_type]["category"]
        icon = NODE_SPECS[node_type]["icon"]
        
        # ì—°ê²° ì •ë³´ ì¶”ê°€
        incoming = [src for src, dst in filtered_edges if dst == node_id]
        outgoing = [dst for src, dst in filtered_edges if src == node_id]
        connection_info = f"ì…ë ¥: {len(incoming)}ê°œ, ì¶œë ¥: {len(outgoing)}ê°œ"
        
        # ë…¸ë“œ ìœ„ì¹˜ ê³„ì‚° (ê·¸ë¦¬ë“œ ìœ„ì¹˜)
        grid_col = i % 3  # 3ì—´ ê·¸ë¦¬ë“œ
        grid_row = i // 3
        x_pos = grid_col * 320 + 160  # 300px ë„ˆë¹„ + 20px gap
        y_pos = grid_row * 200 + 100  # 150px ë†’ì´ + 20px gap
        
        node_positions[node_id] = (x_pos, y_pos)
        
        html += f"""
        <div class="layer" style="border-left-color: {category_color};" data-node-id="{node_id}">
            <div class="category-badge" style="background-color: {category_color};">{category_name}</div>
            <div class="status-check">âœ“</div>
            <div class="layer-header">
                <div class="layer-icon">{icon}</div>
                <div class="layer-name">{node_type}</div>
            </div>
            <div class="layer-id">ID: {node_id}</div>
            <div class="tensor-shape">[{', '.join(map(str, output_shape))}]</div>
            <div class="connection-details" style="margin-top: 10px; font-size: 11px;">{connection_info}</div>
            {f'<div class="params">{param_str}</div>' if param_str else ''}
        </div>
        """
    
    # ì—°ê²°ì„  ê·¸ë¦¬ê¸°
    for src, dst in filtered_edges:
        if src in node_positions and dst in node_positions:
            x1, y1 = node_positions[src]
            x2, y2 = node_positions[dst]
            
            # ê³¡ì„  ì—°ê²°ì„  (ë² ì§€ì–´ ê³¡ì„ )
            mid_x = (x1 + x2) / 2
            mid_y = (y1 + y2) / 2
            
            html += f'''
            <path class="connection-line" 
                  d="M {x1} {y1} Q {mid_x} {y1} {mid_x} {mid_y} T {x2} {y2}"
                  marker-end="url(#arrowhead)" />
            '''
    
    html += "</svg></div></div>"
    return html

# ---------- ì½”ë“œ ìƒì„±ê¸° ----------
def export_graph_to_python(graph: dict, class_name: str="ExportedModel") -> str:
    nodes = graph["nodes"]; edges = graph["edges"]
    inputs = graph["inputs"]; outputs = graph["outputs"]
    node_types = {n["id"]: n["type"] for n in nodes}
    node_params = {n["id"]: n.get("params", {}) for n in nodes}
    in_edges = {n["id"]: [] for n in nodes}
    for src, dst in edges:
        in_edges[dst].append(src)
    # topo sort
    indeg = {n["id"]: 0 for n in nodes}
    adj = {}
    for src, dst in edges:
        indeg[dst] += 1
        adj.setdefault(src, []).append(dst)
    q = [nid for nid, d in indeg.items() if d == 0]
    order = []
    while q:
        u = q.pop()
        order.append(u)
        for v in adj.get(u, []):
            indeg[v] -= 1
            if indeg[v] == 0:
                q.append(v)
    if len(order) != len(nodes):
        raise ValueError("Graph has cycle or disconnected parts.")

    # __init__
    init_lines = []
    for nid in order:
        typ = node_types[nid]
        if typ == "Input":
            continue
        p = node_params[nid]
        if typ == "Conv1d":
            pad = p.get("padding", "same")
            pad_expr = f"{p.get('kernel_size')} // 2" if pad == "same" else str(int(pad))
            init_lines.append(
                f"self.{nid} = nn.LazyConv1d({p['out_channels']}, {p['kernel_size']}, stride={p.get('stride',1)}, padding={pad_expr}, bias=True)"
            )
        elif typ == "Conv2d":
            pad = p.get("padding", "same")
            pad_expr = f"{p.get('kernel_size')} // 2" if pad == "same" else str(int(pad))
            init_lines.append(
                f"self.{nid} = nn.LazyConv2d({p['out_channels']}, {p['kernel_size']}, stride={p.get('stride',1)}, padding={pad_expr}, bias=True)"
            )
        elif typ == "BatchNorm1d":
            num = p.get("num_features", 0)
            if num in (None, 0):
                init_lines.append(f"self.{nid} = nn.LazyBatchNorm1d()")
            else:
                init_lines.append(f"self.{nid} = nn.BatchNorm1d({num})")
        elif typ == "BatchNorm2d":
            num = p.get("num_features", 0)
            if num in (None, 0):
                init_lines.append(f"self.{nid} = nn.LazyBatchNorm2d()")
            else:
                init_lines.append(f"self.{nid} = nn.BatchNorm2d({num})")
        elif typ == "Linear":
            init_lines.append(f"self.{nid} = nn.LazyLinear({p['out_features']}, bias={p.get('bias', True)})")
        elif typ == "ReLU":
            init_lines.append(f"self.{nid} = nn.ReLU(inplace=True)")
        elif typ == "Sigmoid":
            init_lines.append(f"self.{nid} = nn.Sigmoid()")
        elif typ == "Tanh":
            init_lines.append(f"self.{nid} = nn.Tanh()")
        elif typ == "Dropout":
            init_lines.append(f"self.{nid} = nn.Dropout({p.get('p', 0.5)})")
        elif typ == "MaxPool1d":
            ks = p.get("kernel_size", 2); stv = p.get("stride", None)
            args = [f"kernel_size={ks}"]; 
            if stv is not None: args.append(f"stride={stv}")
            init_lines.append(f"self.{nid} = nn.MaxPool1d({', '.join(args)})")
        elif typ == "MaxPool2d":
            ks = p.get("kernel_size", 2); stv = p.get("stride", None)
            args = [f"kernel_size={ks}"]; 
            if stv is not None: args.append(f"stride={stv}")
            init_lines.append(f"self.{nid} = nn.MaxPool2d({', '.join(args)})")
        elif typ == "Flatten":
            start_dim = p.get("start_dim", 1)
            end_dim = p.get("end_dim", -1)
            init_lines.append(f"self.{nid} = nn.Flatten(start_dim={start_dim}, end_dim={end_dim})")
        elif typ == "GRUBlock":
            hs = p["hidden_size"]; nl = p.get("num_layers", 1); bd = p.get("bidirectional", True)
            outm = repr(p.get("out", "last"))
            init_lines.append(f"self.{nid} = GRUBlock(hidden_size={hs}, num_layers={nl}, bidirectional={bd}, out={outm})")
        elif typ == "SEBlock":
            reduction = p.get("reduction", 8)
            init_lines.append(f"self.{nid} = SEBlock(reduction={reduction})")
        elif typ == "ResidualBlock":
            out_channels = p["out_channels"]
            kernel_size = p.get("kernel_size", 3)
            stride = p.get("stride", 1)
            init_lines.append(f"self.{nid} = ResidualBlock(out_channels={out_channels}, kernel_size={kernel_size}, stride={stride})")
        elif typ == "VGGBlock":
            c1 = p["c1"]; c2 = p["c2"]; k = p.get("kernel_size", 3)
            use_lrn = p.get("use_lrn", False); pool = p.get("pool", True)
            init_lines.append(f"self.{nid} = VGGBlock(c1={c1}, c2={c2}, kernel_size={k}, use_lrn={use_lrn}, pool={pool})")
        elif typ in ("Concat","Add","Permute_BCT_to_BTH","Permute_BTH_to_BCT"):
            init_lines.append(f"# {typ} '{nid}' has no parameters")
        else:
            init_lines.append(f"# TODO: Unsupported node type '{typ}'")

    init_body = "\n        ".join(init_lines)

    # forward()
    fwd = []
    fwd.append("cache = {}")
    for inp in inputs:
        fwd.append(f"cache['{inp}'] = inputs['{inp}']")
    for nid in order:
        typ = node_types[nid]
        if typ == "Input":
            continue
        srcs = in_edges[nid]
        if typ == "Concat":
            dim = node_params[nid].get("dim", 1)
            src_list = ", ".join([f"cache['{s}']" for s in srcs])
            fwd.append(f"cache['{nid}'] = torch.cat([{src_list}], dim={dim})")
        elif typ == "Add":
            if len(srcs) != 2:
                raise ValueError(f"Add node '{nid}' requires exactly 2 inputs, got {len(srcs)}")
            fwd.append(f"cache['{nid}'] = cache['{srcs[0]}'] + cache['{srcs[1]}']")
        elif typ == "Permute_BCT_to_BTH":
            fwd.append(f"cache['{nid}'] = cache['{srcs[0]}'].transpose(1, 2).contiguous()")
        elif typ == "Permute_BTH_to_BCT":
            fwd.append(f"cache['{nid}'] = cache['{srcs[0]}'].transpose(1, 2).contiguous()")
        elif typ in ("Conv1d","Conv2d","BatchNorm1d","BatchNorm2d","Linear","ReLU","Sigmoid","Tanh","Dropout","MaxPool1d","MaxPool2d","AvgPool2d","Flatten","GRUBlock","SEBlock","ResidualBlock","VGGBlock"):
            fwd.append(f"cache['{nid}'] = self.{nid}(cache['{srcs[0]}'])")
        else:
            fwd.append(f"# TODO: forward for '{typ}'")
    if len(outputs) == 1:
        fwd.append(f"return cache['{outputs[0]}']")
    else:
        pairs = ", ".join([f"'{k}': cache['{k}']" for k in outputs])
        fwd.append(f"return {{ {pairs} }}")
    fwd_body = "\n        ".join(fwd)

    header = '''# Auto-generated by TorchCanvas Code Export
import torch
import torch.nn as nn
import torch.nn.functional as F

class GRUBlock(nn.Module):
    """
    GRU + output normalization
    - input: (B, T, H_in)
    - out: 'last' | 'mean' | 'max' | 'seq'
    """
    def __init__(self, hidden_size:int, num_layers:int=1, bidirectional:bool=True, out:str="last"):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.bidirectional = bidirectional
        self.out_mode = out
        self.gru = None  # lazy init at first forward

    def forward(self, x):
        if x.ndim != 3:
            raise ValueError(f"GRUBlock expects 3D (B,T,H), got {tuple(x.shape)}")
        if self.gru is None:
            self.gru = nn.GRU(
                input_size=x.size(-1),
                hidden_size=self.hidden_size,
                num_layers=self.num_layers,
                bidirectional=self.bidirectional,
                batch_first=True,
            ).to(x.device, x.dtype)
        y, _ = self.gru(x)
        if self.out_mode == "seq":
            return y
        if self.out_mode == "last":
            return y[:, -1, :]
        if self.out_mode == "mean":
            return y.mean(dim=1)
        if self.out_mode == "max":
            return y.max(dim=1).values
        raise ValueError(f"Unknown out mode: {self.out_mode}")

class SEBlock(nn.Module):
    """
    Squeeze-and-Excitation Block
    - input: (B, C, H, W) or (B, C, T)
    - reduction: channel reduction ratio
    """
    def __init__(self, reduction: int = 8):
        super().__init__()
        self.reduction = reduction
        self.avg_pool = None
        self.fc1 = None
        self.fc2 = None
        
    def forward(self, x):
        if self.avg_pool is None:
            # Lazy initialization based on input shape
            if x.ndim == 4:  # (B, C, H, W)
                self.avg_pool = nn.AdaptiveAvgPool2d(1)
            else:  # (B, C, T)
                self.avg_pool = nn.AdaptiveAvgPool1d(1)
            
            channels = x.size(1)
            self.fc1 = nn.Linear(channels, channels // self.reduction).to(x.device, x.dtype)
            self.fc2 = nn.Linear(channels // self.reduction, channels).to(x.device, x.dtype)
        
        # Squeeze
        if x.ndim == 4:
            y = self.avg_pool(x).squeeze(-1).squeeze(-1)  # (B, C)
        else:
            y = self.avg_pool(x).squeeze(-1)  # (B, C)
        
        # Excitation
        y = F.relu(self.fc1(y))
        y = torch.sigmoid(self.fc2(y))
        
        # Scale
        if x.ndim == 4:
            return x * y.unsqueeze(-1).unsqueeze(-1)
        else:
            return x * y.unsqueeze(-1)

class ResidualBlock(nn.Module):
    """
    Residual Block with optional projection
    - input: (B, C, H, W) or (B, C, T)
    - out_channels: output channels (if different from input, uses 1x1 projection)
    """
    def __init__(self, out_channels: int, kernel_size: int = 3, stride: int = 1):
        super().__init__()
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.conv1 = None
        self.bn1 = None
        self.conv2 = None
        self.bn2 = None
        self.projection = None
        
    def forward(self, x):
        if self.conv1 is None:
            # Lazy initialization
            in_channels = x.size(1)
            padding = self.kernel_size // 2
            
            if x.ndim == 4:  # 2D
                self.conv1 = nn.Conv2d(in_channels, self.out_channels, self.kernel_size, 
                                     stride=self.stride, padding=padding, bias=False).to(x.device, x.dtype)
                self.bn1 = nn.BatchNorm2d(self.out_channels).to(x.device, x.dtype)
                self.conv2 = nn.Conv2d(self.out_channels, self.out_channels, self.kernel_size,
                                     padding=padding, bias=False).to(x.device, x.dtype)
                self.bn2 = nn.BatchNorm2d(self.out_channels).to(x.device, x.dtype)
                
                if in_channels != self.out_channels or self.stride != 1:
                    self.projection = nn.Conv2d(in_channels, self.out_channels, 1, 
                                              stride=self.stride, bias=False).to(x.device, x.dtype)
            else:  # 1D
                self.conv1 = nn.Conv1d(in_channels, self.out_channels, self.kernel_size,
                                     stride=self.stride, padding=padding, bias=False).to(x.device, x.dtype)
                self.bn1 = nn.BatchNorm1d(self.out_channels).to(x.device, x.dtype)
                self.conv2 = nn.Conv1d(self.out_channels, self.out_channels, self.kernel_size,
                                     padding=padding, bias=False).to(x.device, x.dtype)
                self.bn2 = nn.BatchNorm1d(self.out_channels).to(x.device, x.dtype)
                
                if in_channels != self.out_channels or self.stride != 1:
                    self.projection = nn.Conv1d(in_channels, self.out_channels, 1,
                                              stride=self.stride, bias=False).to(x.device, x.dtype)
        
        identity = x
        if self.projection is not None:
            identity = self.projection(x)
        
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += identity
        out = F.relu(out)
        
        return out

class VGGBlock(nn.Module):
    """
    VGG-style block: Conv-ReLU-Conv-ReLU-(Pool)
    - input: (B, C, H, W) or (B, C, T)
    - c1, c2: channel counts for two conv layers
    """
    def __init__(self, c1: int, c2: int, kernel_size: int = 3, use_lrn: bool = False, pool: bool = True):
        super().__init__()
        self.c1 = c1
        self.c2 = c2
        self.kernel_size = kernel_size
        self.use_lrn = use_lrn
        self.pool = pool
        self.conv1 = None
        self.bn1 = None
        self.conv2 = None
        self.bn2 = None
        self.pool_layer = None
        
    def forward(self, x):
        if self.conv1 is None:
            # Lazy initialization
            in_channels = x.size(1)
            padding = self.kernel_size // 2
            
            if x.ndim == 4:  # 2D
                self.conv1 = nn.Conv2d(in_channels, self.c1, self.kernel_size, padding=padding, bias=False).to(x.device, x.dtype)
                self.bn1 = nn.BatchNorm2d(self.c1).to(x.device, x.dtype)
                self.conv2 = nn.Conv2d(self.c1, self.c2, self.kernel_size, padding=padding, bias=False).to(x.device, x.dtype)
                self.bn2 = nn.BatchNorm2d(self.c2).to(x.device, x.dtype)
                if self.pool:
                    self.pool_layer = nn.MaxPool2d(2, 2).to(x.device, x.dtype)
            else:  # 1D
                self.conv1 = nn.Conv1d(in_channels, self.c1, self.kernel_size, padding=padding, bias=False).to(x.device, x.dtype)
                self.bn1 = nn.BatchNorm1d(self.c1).to(x.device, x.dtype)
                self.conv2 = nn.Conv1d(self.c1, self.c2, self.kernel_size, padding=padding, bias=False).to(x.device, x.dtype)
                self.bn2 = nn.BatchNorm1d(self.c2).to(x.device, x.dtype)
                if self.pool:
                    self.pool_layer = nn.MaxPool1d(2, 2).to(x.device, x.dtype)
        
        x = F.relu(self.bn1(self.conv1(x)))
        if self.use_lrn and x.ndim == 4:
            x = F.local_response_normalization(x, size=5)
        x = F.relu(self.bn2(self.conv2(x)))
        if self.use_lrn and x.ndim == 4:
            x = F.local_response_normalization(x, size=5)
        if self.pool and self.pool_layer is not None:
            x = self.pool_layer(x)
        
        return x
'''
    cls = f"""
class {class_name}(nn.Module):
    def __init__(self):
        super().__init__()
        {init_body}

    def forward(self, inputs: dict):
        {fwd_body}
"""
    main = """
if __name__ == "__main__":
    # quick smoke test
    model = ExportedModel()
    x = torch.randn(4, 3, 224, 224)  # (B,C,H,W) for 2D or (B,C,T) for 1D
    out = model({"inp": x})
    print("out.shape =", out.shape)
"""
    return header + cls + main

# ---------- ê°œì„ ëœ ì‚¬ì´ë“œë°”: ì‹œê°ì  íŒ”ë ˆíŠ¸ ----------
st.sidebar.title("ğŸ¨ TorchCanvas â€” Palette")

# ì¹´í…Œê³ ë¦¬ë³„ íŒ”ë ˆíŠ¸
selected_category = st.sidebar.selectbox(
    "ì¹´í…Œê³ ë¦¬ ì„ íƒ",
    list(CATEGORIES.keys()),
    format_func=lambda x: CATEGORIES[x],
    index=0
)

# ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ë¸”ë¡ë“¤ í‘œì‹œ
st.sidebar.subheader(f"ğŸ“‚ {CATEGORIES[selected_category]}")

# ì¹´í…Œê³ ë¦¬ë³„ ë¸”ë¡ë“¤ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ
category_blocks = [name for name, spec in NODE_SPECS.items() if spec["category"] == selected_category]

for block_name in category_blocks:
    block_spec = NODE_SPECS[block_name]
    
    # ë¸”ë¡ ì¹´ë“œ ìŠ¤íƒ€ì¼
    with st.sidebar.container():
        col1, col2 = st.columns([1, 4])
        with col1:
            st.markdown(f"<div style='text-align: center; font-size: 20px;'>{block_spec['icon']}</div>", unsafe_allow_html=True)
        with col2:
            st.markdown(f"**{block_name}**")
            st.caption(block_spec['description'])
        
        # ë¸”ë¡ ì¶”ê°€ ë²„íŠ¼
        if st.button(f"â• {block_name} ì¶”ê°€", key=f"add_{block_name}"):
            # ìë™ìœ¼ë¡œ ë…¸ë“œ ID ìƒì„±
            base_name = block_name.lower()
            existing_ids = [n["id"] for n in st.session_state.nodes]
            counter = 1
            while f"{base_name}{counter}" in existing_ids:
                counter += 1
            nid = f"{base_name}{counter}"
            
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë…¸ë“œ ì¶”ê°€
            params = {}
            for k, spec in block_spec["params"].items():
                if isinstance(spec, tuple):
                    typ, default = spec
                    if typ == int:
                        params[k] = default if default is not None else 1
                    elif typ == float:
                        params[k] = float(default) if default is not None else 0.5
                    elif typ == bool:
                        params[k] = bool(default) if default is not None else False
                    else:
                        params[k] = default
                elif spec == int:
                    params[k] = 64  # ê¸°ë³¸ê°’
                elif spec == float:
                    params[k] = 0.5
                elif spec == bool:
                    params[k] = True
                elif spec == "same_or_int":
                    params[k] = "same"
                else:
                    params[k] = spec
            
            st.session_state.nodes.append({"id": nid, "type": block_name, "params": params})
            st.rerun()
        
        st.sidebar.divider()

# ê³ ê¸‰ ì„¤ì • (ì ‘ì„ ìˆ˜ ìˆëŠ” ì„¹ì…˜)
with st.sidebar.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì •"):
    st.subheader("ìˆ˜ë™ ë…¸ë“œ ì¶”ê°€")
    with st.form("manual_add_node_form"):
        nid = st.text_input("ë…¸ë“œ ID", placeholder="ì˜ˆ: conv1")
        ntype = st.selectbox("ë…¸ë“œ íƒ€ì…", list(NODE_SPECS.keys()), index=0)
        params_spec = NODE_SPECS[ntype]["params"]
        params = {}
        for k, spec in params_spec.items():
            if spec == int:
                params[k] = st.number_input(k, value=1, step=1)
            elif spec == float:
                params[k] = st.number_input(k, value=0.5, step=0.1, format="%.4f")
            elif spec == bool:
                params[k] = st.checkbox(k, value=False)
            elif spec == "same_or_int":
                mode = st.selectbox(k, ["same", "int"], index=0)
                params[k] = "same" if mode == "same" else int(st.number_input(f"{k} (int)", value=1, step=1))
            elif isinstance(spec, tuple):
                typ, default = spec
                if typ == int:
                    val = st.number_input(k, value=default if default is not None else 0, step=1)
                    params[k] = int(val) if default is not None else (None if val==0 else int(val))
                elif typ == float:
                    params[k] = float(st.number_input(k, value=float(default)))
                elif typ == bool:
                    params[k] = st.checkbox(k, value=bool(default))
                else:
                    params[k] = default
            elif isinstance(spec, list):  # enum
                default = NODE_SPECS[ntype]["params"][k][1] if isinstance(NODE_SPECS[ntype]["params"][k], tuple) else spec[0]
                params[k] = st.selectbox(k, spec, index=spec.index(default) if default in spec else 0)
            else:
                params[k] = st.text_input(k, value=str(spec))
        add = st.form_submit_button("ìˆ˜ë™ ì¶”ê°€")
        if add:
            assert nid, "ë…¸ë“œ IDëŠ” í•„ìˆ˜"
            st.session_state.nodes.append({"id": nid, "type": ntype, "params": params})
            st.rerun()

# ---------- ì‚¬ì´ë“œë°”: ì—£ì§€/ì…ì¶œë ¥ ----------
st.sidebar.subheader("Edges")
if st.session_state.nodes:
    opts = [n["id"] for n in st.session_state.nodes]
    with st.sidebar.form("add_edge_form"):
        src = st.selectbox("src", opts)
        dst = st.selectbox("dst", opts)
        add_e = st.form_submit_button("ì—£ì§€ ì¶”ê°€")
        if add_e:
            st.session_state.edges.append([src, dst]); st.rerun()

st.sidebar.divider()
st.sidebar.subheader("ì…ë ¥/ì¶œë ¥ ì„¤ì •")
all_ids = [n["id"] for n in st.session_state.nodes]
st.session_state.inputs = st.sidebar.multiselect("inputs", all_ids, default=st.session_state.inputs)
st.session_state.outputs = st.sidebar.multiselect("outputs", all_ids, default=st.session_state.outputs)

st.sidebar.divider()
if st.sidebar.button("ê·¸ë˜í”„ ì´ˆê¸°í™”"):
    st.session_state.nodes.clear(); st.session_state.edges.clear()
    st.session_state.inputs.clear(); st.session_state.outputs.clear()
    st.session_state.tensor_shapes.clear()
    st.rerun()

# ---------- ë©”ì¸: íƒ­ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤ ----------
st.title("TorchCanvas â€” ì‹œê°ì  ì‹ ê²½ë§ ë””ìì´ë„ˆ")

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¨ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”", "âš™ï¸ ì½”ë“œ ìƒì„±", "ğŸ“Š ìƒì„¸ ì •ë³´", "ğŸ“‹ í…œí”Œë¦¿"])

with tab1:
    # ë„¤íŠ¸ì›Œí¬ ë‹¤ì´ì–´ê·¸ë¨ í‘œì‹œ (ë” í° í¬ê¸°)
    if st.session_state.nodes:
        st.subheader("ğŸ” ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ ì‹œê°í™”")
        
        # ë„¤íŠ¸ì›Œí¬ í†µê³„ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ ë ˆì´ì–´", len(st.session_state.nodes))
        with col2:
            st.metric("ì—°ê²° ìˆ˜", len(st.session_state.edges))
        with col3:
            st.metric("ì…ë ¥", len(st.session_state.inputs))
        with col4:
            st.metric("ì¶œë ¥", len(st.session_state.outputs))
        
        # ë” í° ë‹¤ì´ì–´ê·¸ë¨ (ê°œì„ ëœ ë²„ì „ ì‚¬ìš©)
        diagram_html = create_network_diagram(
            st.session_state.nodes, 
            st.session_state.edges, 
            st.session_state.tensor_shapes
        )
        st.components.v1.html(diagram_html, height=600, scrolling=True)
        
        # ë¹ ë¥¸ í¸ì§‘ ì˜µì…˜
        st.subheader("ğŸ”§ ë¹ ë¥¸ í¸ì§‘")
        colA, colB = st.columns(2)
        with colA:
            if st.session_state.nodes:
                del_id = st.selectbox("ì‚­ì œí•  ë…¸ë“œ", ["â€”"] + [n["id"] for n in st.session_state.nodes], index=0)
                if del_id != "â€”" and st.button("ë…¸ë“œ ì‚­ì œ"):
                    st.session_state.nodes = [n for n in st.session_state.nodes if n["id"] != del_id]
                    st.session_state.edges = [e for e in st.session_state.edges if e[0]!=del_id and e[1]!=del_id]
                    if del_id in st.session_state.inputs: st.session_state.inputs.remove(del_id)
                    if del_id in st.session_state.outputs: st.session_state.outputs.remove(del_id)
                    if del_id in st.session_state.tensor_shapes: del st.session_state.tensor_shapes[del_id]
                    st.rerun()
        
        with colB:
            if st.session_state.edges:
                idx = st.number_input("ì‚­ì œí•  ì—£ì§€ index", min_value=0, max_value=max(0,len(st.session_state.edges)-1), value=0, step=1)
                if st.button("ì—£ì§€ ì‚­ì œ"):
                    st.session_state.edges.pop(idx)
                    st.rerun()
    else:
        st.info("ë…¸ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.")
        st.image("https://via.placeholder.com/800x400/667eea/ffffff?text=TorchCanvas+Network+Designer", use_container_width=True)

with tab2:
    # ì½”ë“œ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ
    st.subheader("âš™ï¸ PyTorch ì½”ë“œ ìƒì„±")
    
    if st.session_state.nodes and st.session_state.inputs and st.session_state.outputs:
        graph = {
            "version": "0.2",
            "metadata": {"name": "torchcanvas_ui"},
            "nodes": st.session_state.nodes,
            "edges": st.session_state.edges,
            "inputs": st.session_state.inputs,
            "outputs": st.session_state.outputs,
        }
        
        try:
            code_str = export_graph_to_python(graph, class_name="ExportedModel")
            
            # ì½”ë“œ ë¯¸ë¦¬ë³´ê¸°
            st.code(code_str, language="python")
            
            # ë‹¤ìš´ë¡œë“œ ë° í…ŒìŠ¤íŠ¸
            col1, col2 = st.columns([1,1])
            with col1:
                st.download_button(
                    "ğŸ“¥ exported_model.py ë‹¤ìš´ë¡œë“œ", 
                    data=code_str.encode("utf-8"),
                    file_name="exported_model.py", 
                    mime="text/x-python"
                )
            
            with col2:
                st.caption("ğŸ§ª ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸")
                b = st.number_input("Batch", min_value=1, value=4)
                C = st.number_input("Channels(C)", min_value=1, value=3)
                H = st.number_input("Height(H)", min_value=1, value=224)
                W = st.number_input("Width(W)", min_value=1, value=224)
                run = st.button("Forward ì‹¤í–‰")
                if run:
                    ns: Dict[str, Any] = {}
                    try:
                        exec(code_str, ns, ns)
                        ExportedModel = ns["ExportedModel"]
                        import torch
                        m = ExportedModel()
                        x = torch.randn(int(b), int(C), int(H), int(W))
                        y = m({"inp": x})
                        st.success(f"âœ… ì„±ê³µ! ì¶œë ¥ í˜•íƒœ: {tuple(y.shape)}")
                    except Exception as e:
                        st.error(f"âŒ ì‹¤í–‰ ì—ëŸ¬: {e}")
        except Exception as e:
            st.error(f"ì½”ë“œ ìƒì„± ì—ëŸ¬: {e}")
    else:
        st.info("ë…¸ë“œ/ì—£ì§€/ì…ì¶œë ¥ì„ ë¨¼ì € êµ¬ì„±í•˜ì„¸ìš”.")

with tab3:
    # ìƒì„¸ ì •ë³´ (JSON, ë…¸ë“œ/ì—£ì§€ ìƒì„¸)
    st.subheader("ğŸ“Š ìƒì„¸ ì •ë³´")
    
    # ì„œë¸Œíƒ­
    sub_tab1, sub_tab2, sub_tab3 = st.tabs(["ğŸ“‹ ë…¸ë“œ ëª©ë¡", "ğŸ”— ì—£ì§€ ëª©ë¡", "ğŸ“„ Graph JSON"])
    
    with sub_tab1:
        if st.session_state.nodes:
            for i, node in enumerate(st.session_state.nodes):
                with st.expander(f"{i+1}. {node['id']} ({node['type']})"):
                    st.json(node)
        else:
            st.info("ì•„ì§ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with sub_tab2:
        if st.session_state.edges:
            for i, edge in enumerate(st.session_state.edges):
                st.write(f"{i+1}. {edge[0]} â†’ {edge[1]}")
        else:
            st.info("ì•„ì§ ì—£ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with sub_tab3:
        graph = {
            "version": "0.2",
            "metadata": {"name": "torchcanvas_ui"},
            "nodes": st.session_state.nodes,
            "edges": st.session_state.edges,
            "inputs": st.session_state.inputs,
            "outputs": st.session_state.outputs,
        }
        st.code(json.dumps(graph, indent=2, ensure_ascii=False), language="json")

with tab4:
    # í…œí”Œë¦¿
    st.subheader("ğŸ“‹ í…œí”Œë¦¿ ì˜ˆì‹œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ—ï¸ VGG-16 í…œí”Œë¦¿ ë¡œë“œ"):
            vgg16_template = {
                "version": "0.2",
                "metadata": {"name": "vgg16_template"},
                "nodes": [
                    {"id": "inp", "type": "Input", "params": {}},
                    {"id": "b1", "type": "VGGBlock", "params": {"c1": 64, "c2": 64, "kernel_size": 3, "use_lrn": False, "pool": True}},
                    {"id": "b2", "type": "VGGBlock", "params": {"c1": 128, "c2": 128, "kernel_size": 3, "use_lrn": False, "pool": True}},
                    {"id": "b3", "type": "VGGBlock", "params": {"c1": 256, "c2": 256, "kernel_size": 3, "use_lrn": False, "pool": True}},
                    {"id": "b4", "type": "VGGBlock", "params": {"c1": 512, "c2": 512, "kernel_size": 3, "use_lrn": False, "pool": True}},
                    {"id": "b5", "type": "VGGBlock", "params": {"c1": 512, "c2": 512, "kernel_size": 3, "use_lrn": False, "pool": True}},
                    {"id": "flat", "type": "Flatten", "params": {"start_dim": 1, "end_dim": -1}},
                    {"id": "fc1", "type": "Linear", "params": {"out_features": 4096, "bias": True}},
                    {"id": "relu1", "type": "ReLU", "params": {}},
                    {"id": "drop1", "type": "Dropout", "params": {"p": 0.5}},
                    {"id": "fc2", "type": "Linear", "params": {"out_features": 4096, "bias": True}},
                    {"id": "relu2", "type": "ReLU", "params": {}},
                    {"id": "drop2", "type": "Dropout", "params": {"p": 0.5}},
                    {"id": "fc3", "type": "Linear", "params": {"out_features": 1000, "bias": True}},
                ],
                "edges": [
                    ["inp", "b1"], ["b1", "b2"], ["b2", "b3"], ["b3", "b4"], ["b4", "b5"],
                    ["b5", "flat"], ["flat", "fc1"], ["fc1", "relu1"], ["relu1", "drop1"],
                    ["drop1", "fc2"], ["fc2", "relu2"], ["relu2", "drop2"], ["drop2", "fc3"]
                ],
                "inputs": ["inp"],
                "outputs": ["fc3"]
            }
            st.session_state.nodes = vgg16_template["nodes"]
            st.session_state.edges = vgg16_template["edges"]
            st.session_state.inputs = vgg16_template["inputs"]
            st.session_state.outputs = vgg16_template["outputs"]
            st.session_state.tensor_shapes.clear()
            st.success("VGG-16 í…œí”Œë¦¿ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    with col2:
        if st.button("ğŸ—ï¸ ResNet-18 í…œí”Œë¦¿ ë¡œë“œ"):
            resnet18_template = {
                "version": "0.2",
                "metadata": {"name": "resnet18_template"},
                "nodes": [
                    {"id": "inp", "type": "Input", "params": {}},
                    {"id": "conv1", "type": "Conv2d", "params": {"out_channels": 64, "kernel_size": 7, "stride": 2, "padding": "same"}},
                    {"id": "bn1", "type": "BatchNorm2d", "params": {"num_features": 0}},
                    {"id": "relu1", "type": "ReLU", "params": {}},
                    {"id": "pool1", "type": "MaxPool2d", "params": {"kernel_size": 3, "stride": 2}},
                    {"id": "res1", "type": "ResidualBlock", "params": {"out_channels": 64, "kernel_size": 3, "stride": 1}},
                    {"id": "res2", "type": "ResidualBlock", "params": {"out_channels": 128, "kernel_size": 3, "stride": 2}},
                    {"id": "res3", "type": "ResidualBlock", "params": {"out_channels": 256, "kernel_size": 3, "stride": 2}},
                    {"id": "res4", "type": "ResidualBlock", "params": {"out_channels": 512, "kernel_size": 3, "stride": 2}},
                    {"id": "gap", "type": "MaxPool2d", "params": {"kernel_size": 7, "stride": 1}},
                    {"id": "flat", "type": "Flatten", "params": {"start_dim": 1, "end_dim": -1}},
                    {"id": "fc", "type": "Linear", "params": {"out_features": 1000, "bias": True}},
                ],
                "edges": [
                    ["inp", "conv1"], ["conv1", "bn1"], ["bn1", "relu1"], ["relu1", "pool1"],
                    ["pool1", "res1"], ["res1", "res2"], ["res2", "res3"], ["res3", "res4"],
                    ["res4", "gap"], ["gap", "flat"], ["flat", "fc"]
                ],
                "inputs": ["inp"],
                "outputs": ["fc"]
            }
            st.session_state.nodes = resnet18_template["nodes"]
            st.session_state.edges = resnet18_template["edges"]
            st.session_state.inputs = resnet18_template["inputs"]
            st.session_state.outputs = resnet18_template["outputs"]
            st.session_state.tensor_shapes.clear()
            st.success("ResNet-18 í…œí”Œë¦¿ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    st.divider()
    st.subheader("ğŸ“š í…œí”Œë¦¿ ì„¤ëª…")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        **VGG-16**
        - 13ê°œ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ + 3ê°œ ì™„ì „ì—°ê²° ë ˆì´ì–´
        - ì´ë¯¸ì§€ ë¶„ë¥˜ì— íŠ¹í™”
        - ê¹Šì€ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°
        """)
    
    with col2:
        st.markdown("""
        **ResNet-18**
        - ì”ì°¨ ì—°ê²°ì„ ì‚¬ìš©í•œ 18ì¸µ ë„¤íŠ¸ì›Œí¬
        - ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œ í•´ê²°
        - íš¨ìœ¨ì ì¸ í•™ìŠµ ê°€ëŠ¥
        """)
